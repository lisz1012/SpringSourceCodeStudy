# 高并发笔记 （周老师）

## 前言

不要因为技术而技术，要明白为什么要有这个技术，技术的原理，因该怎么用这个技术  
拿着天使投资花在营销上，会赚的更多。很多人就在做营销，手段极其残忍。比如陌陌这个app，有正规渠道可以获知它：  
1. CCTV广告：“陌陌让具有相同爱好的人聚在一起”  
2. 百度买关键字排名  
3. 找微博大V给钱推广  
4. 制造话题营销   
已经从单纯关注流量转向了关注VIP用户和赚会员费  
更多的人下载使用服务，这就带来了高并发的问题  
渠道流量有时候容易被忽略：就是用户从哪个网站的链接上访问的我的网站。日志分析可以得到这个数据，再配合后台交易记录做Join，就可以分析出每个渠道的转化率或者购买力。然后下一轮融资再投广告的时候，  
就往转化率高的渠道投资。JD除了自己卖东西也可以做3P，提供平台服务第三方商家，这时候东哥就可以拿着这个数据给商家，说你为什么转化率少呢？我可以提供服务帮你提高转化率  

中国移动互联网用户7亿，固定端上网用户5亿，一共12亿用户总量（有重复计算），假设20%的人看到了我们的推广，又有20%下载，又有20%付费，这就是1000万用户了，在假设20%的常年高活跃度用户，那就是200万日活，
做到这个已经很不容易了。所以企业要想做的好，必须处理上万甚至百万级并发。下面引出技术

## 技术部分

### 网络协议参考模型

高并发的技术主要有两大类：4层技术和7层技术（OSI参考模型）  
应用层：用户接口，比如浏览器tomcat。其中的协议有http，https，smtp，ssh.例子：```cd /proc/$$/fd```  $$是当前进程（当前cmd shell）fd是文件描述符。```ll```会出现0，1，2，分别表示输入输出和报错  
       ```exec 8<> /dev/tcp/www.baidu.com/80```此时再次执行```ll```发现出现了一个编号为8的socket。这一点可见linux系统真的是“一切皆文件”，看似一个文件/dev/tcp/www.baidu.com/80 ，其实在
       内核之中会转化成一个套接字，也就是说已经和baidu建立了一次握手创建出了一个通信了。这时执行```echo -e 'GET / HTTP/1.0\n' >& 8``` '&'表示后面跟的不是文件而是文件描述符8，-e选项会识别\n变成
       换行符。```'GET / HTTP/1.0\n'```就是http协议里面规定的request请求头最小的写法。echo完了之后重定向给socket，也就是发送给百度，然后百度会返回response到8这个文件描述符。此时执行
       ```cat 0<& 8```就可以看到返回的页面文本。但是整个过程要快，可以先关掉8这个文件描述符再重新来：```exec 8<& -```第一步建立连接，第二步才是传送数据，传送数据的时候用http协议规范，以上就是应用
       层协议：符合规范的字符串。手写GET / HTTP/1.0就是模拟浏览器。而浏览器只是把数据内容写规整了，而不是直接发走数据，他只是调下面的层次去了，他调用传输控制层，告诉他想和百度传输数据，你先帮我建立连
       接（socket），我在把数据传输过去，然后百度传回来数据，浏览器再进行渲染变成图形。应用层是用户态，而下面的都在内核态。建立连接会调用底层native代码  
表示层：协议语意，段落划分，字符串的表示，加密  
会话层：session控制
传输控制层：如何让传输确认成功或者失败（TCP/UDP）跟具体的应用程序无关，所有应用程序都会来调用。  
1. TCP，面向连接的可靠的协议。发过去就发回来确认。三次握手和四次分手+确认机制，  
	三次握手：先看对面女生一眼，女生回看一眼，说明她也有意思，此时如果我不再看女生了，那说明没看上，无法建立连接，如果我再次回看她，
	那好，确认过眼神，连接建立！最后一次握手不可少，得让人家姑娘明白我对人家也有意思，踏实了！三次握手成功的话，双方都能确定自己的输入和输出都没问题。三次握手之后才会开辟线程，对象，描述符等相应的资源。也就
	是说三次握手会使资源带来消耗。建立连接之后的传输数据有确认机制，就是每发送一个数据包就有一个确认，所以可靠。  
	四次分手：为什么分手？资源有限。总共65535个端口，一点都不多。也就是说，一台计算机，相同时访问100000个不同的网址，对不起，建立不起来，总共65535个端口可以向外建立连接。客户端在65535之内随机申请到一个
	端口号，他如果用完了不还回去，端口资源就没了，再接下去就无法建立连接了。分手为什么是4次？两个人好不容易结婚了，结婚就意味着有法律的义务了，不是说离婚就能离婚的，必须征求意见，离婚之前还要进行义务。分手不
	是一方的事情。1.客户端说：我想断开连接。2.服务器说：确认了，我知道你想分手这个心思了。此时服务器有两种可能，一种是服务器也想分开了，说一句，我也想分手，然后客户端再发回一个确认。只有两端都发现了自己和对
	方都想分手之后，再随机等一个时间片，两者才会把各自的内存回收，有礼貌地妥善处理，谁也不辜负谁。结论：三次握手再传输数据最后四次分手，这称为最小粒度，不可被分割。比如说：客户端c1连接负载均衡的两个server，
	s1和s2，三次握手一定是都发生在c1与s1（或者三次都发生在c1与s2）之间。你不能c1和s1谈了十年恋爱，人家s1就等一个结婚证了，结果最后c1跟s2上来就同房...不带这么坑的。所以说三次握手不能拆开，端点与端点之间
	的传输数据时不能被打散的。连接不是物理的。从TCP往下每一层都有协议和表格，可以用```netstat -natp``` （其中n是ip地址不要用于逻辑名称的显示，a是所有，t是tcp，p是pid，进程号）看所有的连接。一个socket
	就是一个IP:port. 一个IP:port表示一个独立的连接192.168.150.14:22 - 192.168.150.1:53815 和 192.168.150.14:22 - 192.168.150.1:60277是不一样的，数据的传输不互相影响。传输控制层会创建各种数
	据包，但他依然没有能力直接发出去，因为最终是通过物理的网卡发出去的，其他几个层还要参与，传输控制层还要调用下面的。当下比较火的：微服务，Service Mesh（未来），中台（服务治理）  
2. UPD，非面向连接的不可靠的  

网络层：设备中如何去路由，如何找到节点，如何通信，数据包怎么发。```cat /etc/sysconfig/network-scripts/ifcfg-eht0```读取eht0网卡信息if是interface的意思。出来的信息里面有4个维度：IP，掩码，网关，DNS
 
1. IP：主机的坐标  
2. 掩码：拿着IP和掩码做按位与（位运算是计算机里面运算速度最快的），就会得到网络号：255.255.255.0 & 192.168.150.14 = 192.168.150.0
3. Gateway："下一跳"地址。每台机器不存储整个网络的拓扑结构，而是存储“下一跳”，一个网络里面的机器只看到他的网关，看不到外部网络其他的所有机器。网关接到里面机器传来的数据包之后，根据路由表的判定，扔给相应的
	一步之遥的下一跳的机器，最终一跳一跳的到目标机器。所以，内存中只存储一步之内的机器，省内存和菜谱，不需要图计算了。最终有资本推动了这个tcp/ip的协议。查看路由表，mac：```netstat -rn``` Linux:
	```route -n```目标IP与各个条目的mask做按位与运算，如果结果与“Destination”一致，则这一条的Gateway即为“下一跳”的机器，一般来说家庭网络的gateway就是路由器地址。mask=0.0.0.0, Destination=0.0.0.0
	对应的Gateway就是默认网关了。Gateway=0.0.0.0的意思是跟destination在一个网络里面，不用“下一跳”。ping百度的时候，目标地址当然写百度的IP，但是怎样通过“下一跳”正确的找到百度呢？看下面的链路层～   
	
链路层：点点之间用什么协议，写出一个什么样的东西能发到对方那里去（PPPoE）。链路层会在网络层数据包之外再套一层，地址写上mac，下一跳的网卡地址.```arp -a```IP地址和网卡硬件地址的映射。DNS是全网的逻辑域名到IP地址
	   arp是同一局域网内的。mac地址是下一跳给谁，往里面一层是目标IP，再往里面是port，给哪个进程，一共三个地址，确定了最后给目标地址的哪个进程。所以每跳一次，只有下一跳mac地址发生变化。有多个“下一跳”的时候，
	   怎么确定走哪个呢？这个是有网络工程师来确定的。开放路由协议可以简单化出附近的网络拓扑。(顺便说一下5G，末端信号塔和手机间的通信延迟有几十毫秒变成了1毫秒，支持的设备数量也更多了)arp协议中的目标mac地址很特殊：
	   FFFFFFFF，arp的目标IP是网关。包进到交换机之后，交换机会广播到除了入口之外的另外的口，这样就给了路由器和另外的计算机，另外的计算机就把数据包丢弃，路由器会做出响应，此时根据arp协议，路由器会回复发数据的
	   计算机一个arp包，把IP换成源IP，mac地址也换成源mac地址返回去，且带了路由器自己的mac地址。交换机有学习能力，知道哪个口接的是哪个mac地址，所以当数据包从路由器发回来的时候，交换机就直接找到源mac所对应的口，
	   从那里发回去，不再广播了。由于数据包里面带了路由器的mac地址，所以收到返回包之后, 源机器就知道了下一跳路由器的mac地址  
	   实验一台主机192.168.1.120加一个虚拟网卡 ```ifconfig ens33:3 192.168.88.88/24```, 另一台主机想访问新网卡，要加一个路由条目：```sudo route add -host 192.168.88.88 gw 192.168.1.120```
	   才能ping通192.168.88.88。另一台主机的路由条目多了一条：```192.168.88.88   192.168.1.120   255.255.255.255 UGH   0      0        0 eth3```  
	   Tomcat和Nginx都是在应用层，所以数据传输到对面的地址要走所有的层，性能不是很高，想到应用层，传输控制层必须完成三次握手，最后还得4次分手，用户态内核态还有切换。Tomcat在JVM上，在应用层又虚拟出一层，再多
	   切换一次，所以Tomcat比其他的应用程序，比如nginx，更低。如果做负载均衡的时候，中间的那个节点只有三层，不走7层，没有用户态内核态的切换，立刻转走，这样就会大大提升性能，约等于这个设备就是比网线稍微慢了一
	   点点。注意：这不是反向代理，反向代理要跟中间的这个节点有握手，而这种情况是3层结构，握手没有跟中间节点握。中间的节点可以叫做“负载均衡器”，握手时负载均衡器不参与，客户端直接跟服务器握手。在第四层只是看了看
	   port，因为他要知道那些包该转发到后面server那些不该，所以他要偷窥一下port，比如80端口号，那就要往后面传，做负载均衡，8080就自己留着了。所以负载均衡器到了四层又没到四层，要求是特别快，数据包转发这个级别
	   的，不会跟客户端握手。好处是快，坏处是不知道用的是什么协议，这就要求后端服务器是镜像的，也就是说后面的各个server都是一致的。nginx后面的server是可以不一样的，一个是购物车，另一个是用户系统，它可以拆解，
	   基于反向代理之后可以做一个负载均衡，可以把一个购物车变成十个server。3/4层负载均衡器就不行，不握手不知道uri。想知道URI，nginx必须要跟客户端握手，所以nginx处理的并发是有上限的，官方说是50000，但是lvs，
	   只要硬件够快，带宽够大，组网模式合适，他的速度和可以应付的流量要远大于nginx。所以一般在企业应用中，最前端是lvs，hold住流量，然后再来一层nginx，hold住握手，然后收到所有请求之后，nginx再转到后面的计算层：
	   一大票的Tomcat
	     
物理层：wifi，4G，5G，光纤等设施很多，每种设施的协议还不一样  

5层协议中，会话层和表示层就被并入了应用层  

软件工程学的精髓是分层解耦，只要对上面的接口不变，下面的实现可以做任何改进


### 高访问量下的负载均衡理论

#### 铺垫：NAT（Network Address Translation）  

NAT是网络地址转换的意思。我们用路由器上网的时候大概就是用的这种机制。比如说：我们电脑在局域网里的网址是```192.168.1.8```，路由器是默认网关，他有两个网卡，对内连接有个网卡，对外的公网也有个网卡，连接两个网络对内网的机器
们充当网关，地址是192.168.1.1，对外网的IP是6.6.6.6,而Google网页服务器网址假设是8.8.8.8, 则我的电脑访问Google的时候写请求数据包，网络层是这么写的：从```192.168.1.8:12121``` （随机端口12121）发送到
```8.8.8.8:80```；链路层的mac地址：从我的电脑的MAC发给路由器的MAC。此时路由器由于是下一跳的目的地，则它会收到包，然后由于要做NAT，所以他不但要修改源和目的MAC地址，还要修改源IP和端口，比如修改为自己的公网IP和端口号：
```6.6.6.6:123```，并记下```6.6.6.6:123 -> 192.168.1.8:12121``` 这一映射关系，然后再把数据包转发出去，找公网上的下一跳，直到到达Google的```8.8.8.8:80```。当Google拿到请求数据包的时候，发现源IP是路由器的
```6.6.6.6:12121```, 目的地地址是：```8.8.8.8:80```，在返回数据的时候，把它的源和目的地地址调换，将页面data写进数据包返回，于是页面数据会返回到路由器的```6.6.6.6:123```端口，然后查到123端口所映射的IP地址和端口号：
```192.168.1.8:12121```，再改目标IP和端口为```192.168.1.8:12121```，再转发给我们的电脑，这时我们的电脑核实源地址为Google的```8.8.8.8:80```，目的地为本机```192.168.1.8:12121```，没有错误，接收成功！NAT由于
动了IP地址，所以它是基于3层协议的。实现这个有个要求，real server的默认网关指向负载均衡服务器  

#### 基于2层协议的DR，mac地址欺骗（重点实现）

NAT的一个缺点是数据的上行和下行不对称，一般request数据包很小，而返回的data页面一般又很大，如果用NAT，相当于一条公路，早上上班的时候人人骑自行车过去，但回来的时候大家都开卡车回家，肯定拥堵。这时就不能用NAT的方式了，
原因就是访问量上来的，这个变化不像自家的网络那样承受得了了。名词声明 Client 地址：CIP 服务端网络虚拟IP：VIP 服务端服务器的真实IP：RIP  
客户端发请求到服务器的数据包：CIP -> VIP 服务端只暴露公网IP，其实是个虚拟的IP，叫VIP。当数据包来到VIP的负载均衡器的时候，他要发送给他后面的各个server，RIP。但是此时如果像NAT一样改IP则一个是慢了（因为算力浪费），
一个是改IP的话又会原路返回，产生负责均衡器上的数据拥堵。所以想出了个办法：修改各个服务器的内核，设置自己的IP为VIP，但是使其对外隐藏自己的VIP，以避免冲突。对于负载均衡器，他要修改下一跳的MAC地址为某个server的MAC地址，
注意，不是IP，这时只是两层协议。然后这个真是服务器得到的IP层的数据仍然是：CIP -> VIP，他在颠倒两者返回给客户端，则客户端看到后觉得有来有回，正确无误，所以就会接受了。这时返回的数据包并没有走负载均衡器，所以不会对其造成
返回数据上的压力。但是这么做有个约束：由于只是基于2层协议，所以负载均衡器和真实的服务器必须只有一跳的距离，所以她们必须在同一个局域网。问题：还是用D-NAT，只是RIP发回去的时候，源IP换成VIP不就行了？第一，只要是NAT，就要改
IP和端口号，则协议成了三层的，慢了。第二，... 下节课再说

还有负载均衡器本身是个single point，这个有keepalive可以做它的负载均衡（负载均衡的负载均衡），多个RIP的mac怎么选择？后面讲（静态负载和动态负载）  

#### 隧道模式

上面DR的模式有个缺点：负载均衡器必须要和real server在一个机房里，中间如果有跳点的话就不行了。下面介绍隧道技术。上面负载均衡器收到CIP -> VIP的数据包的时候，在他的外面再套一层DIP -> RIP的数据包，然后就可以多次跳跃了，
只是到最后RIP收到的时候，要先撕掉外层的数据包，然后再查看里面的数据包，就看见CIP -> VIP了，然后颠倒回去，就可以建立socket返回数据了。隧道技术就是IP数据包背着IP数据包的过程。这一点跟VPN或者翻墙比较相似  

### lvs四层负载均衡

#### 原理

负载均衡并不增加单一吞吐量，而是将并发分治了。 Linux的/proc目录是个虚拟目录，只有启动之后才有这个目录下的东西，它放的是Linux内核和所有启动的进程，把里面的变量和参数抽象成文件放在这个目录下面。现在修改文件里面的值就约等于
改了内核里面的参数的值，文件里面的数值一变，内核立刻体现效果。Linux就是把内存中的变量或者参数映射成了硬盘上的文件（选择性的暴露），所以可以通过修改文件内容而修改内核程序里的参数或变量的内容。但是这里面的文件不能用vim打开，
会像office打开word文件那样产生一个临时文件，这个等于是要动地址空间了，所以这个目录下的文件只能用echo重定向去覆盖。/proc目录没有再次攀上，而是内存里的一个树状的存储结构。开机之后有了内核和进程才有了其下的子目录。我们这里
要做修改的是:  
```/proc/sys/net/ipv4/conf/*IF*/```  
最后的“IF”是interface的意思，针对哪一块具体的网卡去改内核里面的协议的配置，在这个目录下会有两个文件(内核arp协议中的两个参数，默认值都是0)：  
1. arp_ignore ：定义收到ARP请求的响应级别：0表示只要本地配置有相应的地址，就予以响应；1表示仅在请求的目标（MAC）地址配置请求到达接口上的时候，才予以响应。一台主机有俩网卡1和2，对于网卡2的请求可能发到了1上，要不要响应？  
				一台主机这就好比一个家庭，有人问我手机号是多少？我直接告诉他；有人问我老婆手机号是多少？如果是男的问，让他玩儿去；如果女生问，就说还没结婚呢。反正也是不告诉对方。（周老师这里太幽默啦）这就是对外隐藏对内可见  
2. arp_announce ：定义自己地址向外通告时的通告级别。0表示将本地任何接口上的任何地址向外通告，网卡只要加电就要往外面输出；1表示试图仅向目标网络通告与其网络匹配的地址；2表示仅向与本地接口上地址匹配的网络进行通信。常识：
				一块物理网卡上可以配多个不同的IP地址。一块网卡上插了一根物理网线，但会有几个IP地址，如果网线的另一端也有几个IP地址的话，和这边有相对应的，就可以通信了。通信的时候一定要保证地址是有相同的网络号的.跟IP1
				相连的网络不知道还有IP2，跟IP2相连的那个网络不知道还有IP1. 这就好比一个家庭中，老公有两部手机，老婆只知道其中一部手机的手机号。级别0是有人问老公的手机号，老公把自己的两个手机号和老婆的手机号全告诉别人了，
				有点缺心眼，没必要公布老婆的联系方式；级别1是有人问老公的手机号，老公把自己的两个手机号和老婆的手机号全告诉别人了，也不太合适，合适的手机联系合适的人，对内手机联系家人，对外的手机联系其他的人；级别1是有人
				问老公的手机号，老公只告诉对方自己对外联系的手机号，这样信息分类清楚，且最安全 ^_^。  
				
eth0和lo都是网卡，只不过前者是物理网卡，后者是虚拟网卡，lo是内核中的一段代码，虚拟出来模拟的一个网卡。启动一个tomcat，自己部署一个网站，在自己的浏览器中访问localhost:8080的时候访问的就是lo，数据包进入到内核之后，做路由
判定，一看就是自己的地址，就走到这个lo网卡，这个lo网卡有个能力就是直接loop back，调头发回操作系统，输出包变成了输入包，拿到输入包一看目的地正确，找到8080端口tomcat响应。这里不插网线都没关系。返回的response数据包也是一
调头又返回给了浏览器。同样原理，内核上的虚拟网卡是不能插网线的，也说不出去自己的IP地址，外界的数据包只能到达物理网卡的端口，到达不了虚拟网卡。任何接口都可以有子接口，其实可以在lo上做一个子接口，就是给lo配置一个子IP，把这个
子IP配置成VIP就可以了。这样的话，物理网卡通过改内核不让它往外说VIP的地址，VIP那个虚拟网卡自己也没有能力往外说，所以秘密就保守住了，只有内核知道这块网卡地址，对外隐藏，对内可见的目的就达到了。这是结论就出来了：  
我们要调内核且VIP要配置在环回接口lo上。 

静态负载均衡：有轮询，带权重的轮询等等。  
动态负载均衡：  
- 1. lc，最少连接数。给连接数最少的服务器，四层负载均衡器不会跟client握手，client和真实的server之间才会有握手。负载均衡器有“偷窥”能力，能够看一下client发过来的握手包sync里的源IP和port，转发给一台server，server1，然后
	记录下来client:port 的握手包给了server1；当server1给出返回client确认包的时候（根据模型，有可能通过或者不通过负载均衡器回到clien，这个不重要），client还要发一个ack包，要经过负载均衡器，如果负载均衡器偷窥了client
	第一次发的sync握手包，以及他后续的ack包，这时候负载均衡器就会给server1的连接计数 + 1，认为有一个连接和server1建立好了。这时候不可能只增不减，所以同理当任意一方发送fin包并最后确认的时候，负载均衡器会将该server上的
	连接计数-1.
- 2. wlc，带权重的lc...  

现在的Lunix操作系统默认都带着lvs负载均衡的模块，它的模块的名称叫做ipvs，安装交互接口：```yum install ipvsadm -y``` 有了这个软件会把我们的指令翻译成C语言API的指令，然后调用内核ipvs模块，这样就生效了。配置要配两次：
输入和输出。管理集群服务：，添加：```-A -t|u|f SERVICE_ADDRESS [-s scheduler]``` -t：TCP协议的集群 -u: UDP协议的集群 SERVICE_ADDRESS： IP:PORT -f: FWM 防火墙标记。修改: -E 删除：-D -t|u|f SERVICE_ADDRESS
例子：```ipvsadm -A 192.168.1.120:80 -s rr```  

管理集群中的Real Server（RS）  
添加： -a -t|u|f SERVICE_ADDRESS -r SERVER_ADDRESS [-g|i|m] [-w weight]  
-t|u|f SERVICE_ADDRESS: 事先定义好的某集群服务  
-r SERVER_ADDRESS：某Real server的地址。在NAT模型中，可食用IP:PORT事先端口映射。  
[-g|i|m]：LVS类型：  
-g：DR  
-i：TUN  
-m：NAT  
[-w weight]：定义服务器的权重  
修改：-e  
删除：-d -t|u|f SERVICE_ADDRESS -r SERVER_ADDRESS  
```
ipvsadm -a -t 172.16.100.1:80 -r 192.168.10.8 -g  
ipvsadm -a -t 172.16.100.1:80 -r 192.168.10.9 -g
  
每增加一台real server就得重写一遍上面的命令  
查看  
 -L|l  
 -n: 数字格式显示主机地址和端口  
 --status：统计数据  
 --rate：速率  
 --timeout：显示tcp，tcpfin和udp的会话超时时长  
 -c：显示当前的ipvs连接状况(lvs不跟客户端相连接，只是偷窥到的连接情况)  
删除所有的集群服务  
 -C：清空ipvs规则  
 -S：保存规则  
ipvsadm -S > /path/to/somefile  
 -R: 载入此前的规则：  
ipvsadm -R < /path/from/somefile  
``` 

#### 实操部分

lvs负载均衡服务器要配置一个eth0:1 其VIP是192.168.8.100；Real Servers要配置一个lo:2 其VIP也是192.168.8.100。所有的DIP，VIP都在一个虚拟网络的网段里，因为这里我们用的是DR的方式。一个网卡可以配多个IP，
只要有对的IP，数据包就一定能进来的  
VMWare不仅仅虚拟主机还虚拟出一个网络：192.168.8.2，所以所有Real server和lvs服务器IP都要在192.168.8.0 这个网段，有个windows守护进程支持这个网络。192.168.8.1也是Windows虚拟出来的，好让我们的Windows能跟这个虚拟
的网络通信，否则windows浏览器和ssh访问不了虚拟网络。192.168.8.x的各台机器使用NAT连接方式，把网关设置成192.168.8.2。虚拟网络中的机器也跟192.168.1.102这个物理以太网网卡做了一次地址转换，真正发包的时候改写源地址为
192.168.1.102  

做lvs负载均衡的机器配一个虚拟网卡：  
```ifconfig eth0:2 192.168.8.100/24``` 或者
```ifconfig eth0:2 192.168.8.100 netmask 255.255.255.0```  
如果想删除这个网卡，可以```ifconfig eth0:2 192.168.8.100 down```  

配置各个real server的时候要注意一个顺序：要先去修改内核，调整arp协议，隐藏真实IP，然后再配置VIP：192.168.8.100 否则就藏不住了：  
```cd /proc/sys/net/ipv4/conf```  
```cd eth0```  
然后修改arp_ignore和arp_announce, 不要用vim:  
```echo 1 > arp_ignore```  
```echo 2 > arp_announce```  
然后```cd ../all``` 继续再次执行上面两个命令。这样arp协议就配置好了，然后就是把VIP配置在环回接口lo上：```ifconfig lo:2 192.168.8.100 netmask 255.255.255.255```注意这次的netmask是255.255.255.255，因为
如果是255.255.255.0 则它跟192.168.8.12做与运算之后得到192.168.8.0，此时它发出的数据包也可以进入192.168.8.0这个网络，此时ping 192.168.8.1的时候，从两个地址192.168.8.12和192.168.8.100都可以出去，又由于虚拟网卡
比物理网卡距离内核更近，则数据包会从192.168.8.100这个环回接口发出来，而环回接口可以发回给自身，则这个ping数据包就永远发不出去了；255.255.255.255和192.168.8.100做与运算，网络号叫做192.168.8.100，而不是192.168.1.0
这样数据包就通过192.168.8.12发出去了。这样是规避死循环这个风险。  
然后安装apache的web server： ```yum install httpd -y```   
然后在real server上启动：```service httpd start```  
然后```vim/var/www/html/index.html```然后再输入"From 192.168.8.x"(从哪台机器上就写那台机器)  

转到lvs负载均衡服务器安装ipvs：  
```yum install ipvsadm -y```  

然后是先添加进来的数据包的规则：
```ipvsadm -A -t 192.168.8.100:80 -s rr```  
现在只有一个VIP的规则却没有负载的real server，下面配置real server(出去的包的规则)：  
```ipvsadm -a -t 192.168.8.100:80 -r 192.168.8.12 -g -w 1``` (-g轮询，-w设置权重为1)  
再配置一个real server：
```ipvsadm -a -t 192.168.8.100:80 -r 192.168.8.13 -g -w 1```查看配置情况：  
```ipvsadm -ln```  
实例：  
```
[root@master Desktop]# ipvsadm -A -t 192.168.8.100:80 -s rr
[root@master Desktop]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.8.100:80 rr
[root@master Desktop]# ipvsadm -a -t 192.168.8.100:80 -r 192.168.8.12 -g -w 1
[root@master Desktop]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.8.100:80 rr
  -> 192.168.8.12:80              Route   1      0          0         
[root@master Desktop]# ipvsadm -a -t 192.168.8.100:80 -r 192.168.8.13 -g -w 1
[root@master Desktop]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.8.100:80 rr
  -> 192.168.8.12:80              Route   1      0          0         
  -> 192.168.8.13:80              Route   1      0          0         
[root@master Desktop]# ipvsadm -ln
IP Virtual Server version 1.2.1 (size=4096)
Prot LocalAddress:Port Scheduler Flags
  -> RemoteAddress:Port           Forward Weight ActiveConn InActConn
TCP  192.168.8.100:80 rr
  -> 192.168.8.12:80              Route   1      0          0         
  -> 192.168.8.13:80              Route   1      0          0
```  
验证：
浏览器中访问192.168.8.100 查看from哪个IP，应该是交替的出现"from 192.168.8.12"和"192.168.8.13", 疯狂刷新页面，在两个real server处看到又80端口的很多连接，但是在lvs服务器上却没有，这说明他只是“偷窥”，只是建立在两层
协议上的。如下：

```
======================= 192.168.8.12 ==============================================

[root@master all]# netstat -natp
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name   
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      2077/sshd           
tcp        0      0 :::80                       :::*                        LISTEN      3499/httpd          
tcp        0      0 :::22                       :::*                        LISTEN      2077/sshd           
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56013    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:55986    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56001    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56007    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56019    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:55989    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56015    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56017    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56005    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56011    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56003    TIME_WAIT   -                   


======================= 192.168.8.13 ==============================================

[root@master network-scripts]# netstat -natp
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address               Foreign Address             State       PID/Program name   
tcp        0      0 0.0.0.0:22                  0.0.0.0:*                   LISTEN      2071/sshd           
tcp        0      0 192.168.8.13:47386          172.217.31.163:443          TIME_WAIT   -                   
tcp        0      0 192.168.8.13:47385          172.217.31.163:443          TIME_WAIT   -                   
tcp        0      0 :::80                       :::*                        LISTEN      11240/httpd         
tcp        0      0 :::22                       :::*                        LISTEN      2071/sshd           
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56016    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56012    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56010    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56004    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56018    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56014    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56008    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56002    TIME_WAIT   -                   
tcp        0      0 ::ffff:192.168.8.100:80     ::ffff:192.168.8.1:56006    TIME_WAIT   - 
``` 
